<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¯­éŸ³è¯†åˆ«æµ‹è¯•</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 600px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .voice-btn {
            width: 60px;
            height: 60px;
            border: none;
            background: #4CAF50;
            color: white;
            border-radius: 50%;
            cursor: pointer;
            font-size: 24px;
            margin: 20px auto;
            display: block;
            transition: all 0.3s ease;
        }
        .voice-btn:hover {
            background: #45a049;
            transform: scale(1.1);
        }
        .voice-btn.recording {
            background: #f44336;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        .result {
            margin: 20px 0;
            padding: 15px;
            background: #e8f5e8;
            border-radius: 5px;
            border: 1px solid #4CAF50;
            min-height: 50px;
        }
        .status {
            margin: 10px 0;
            padding: 10px;
            background: #fff3cd;
            border-radius: 5px;
            border: 1px solid #ffc107;
        }
        .error {
            background: #f8d7da;
            border-color: #f5c6cb;
            color: #721c24;
        }
        .success {
            background: #d4edda;
            border-color: #c3e6cb;
            color: #155724;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤ Web Speech API æµ‹è¯•</h1>
        
        <div class="status" id="status">
            æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ...
        </div>
        
        <button id="voiceBtn" class="voice-btn" title="æŒ‰ä½è¯´è¯">
            ğŸ¤
        </button>
        
        <div class="result" id="result">
            è¯†åˆ«ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...
        </div>
        
        <div style="text-align: center; margin-top: 20px;">
            <p><strong>ä½¿ç”¨è¯´æ˜ï¼š</strong></p>
            <p>1. æŒ‰ä½éº¦å…‹é£æŒ‰é’®å¼€å§‹è¯´è¯</p>
            <p>2. æ¾å¼€æŒ‰é’®ç»“æŸè¯†åˆ«</p>
            <p>3. ç¡®ä¿å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£</p>
        </div>
    </div>

    <script>
        let recognition = null;
        let isRecording = false;
        
        const voiceBtn = document.getElementById('voiceBtn');
        const result = document.getElementById('result');
        const status = document.getElementById('status');
        
        // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
        function checkSupport() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                
                // é…ç½®
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'zh-CN';
                recognition.maxAlternatives = 1;
                
                // äº‹ä»¶å¤„ç†
                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    result.textContent = transcript;
                    status.textContent = 'âœ… è¯†åˆ«æˆåŠŸï¼';
                    status.className = 'status success';
                };
                
                recognition.onerror = function(event) {
                    let errorMsg = 'è¯†åˆ«å‡ºé”™ï¼š' + event.error;
                    switch(event.error) {
                        case 'no-speech':
                            errorMsg = 'âŒ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•';
                            break;
                        case 'audio-capture':
                            errorMsg = 'âŒ æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™';
                            break;
                        case 'not-allowed':
                            errorMsg = 'âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»';
                            break;
                        case 'network':
                            errorMsg = 'âŒ ç½‘ç»œé”™è¯¯';
                            break;
                    }
                    status.textContent = errorMsg;
                    status.className = 'status error';
                };
                
                recognition.onstart = function() {
                    status.textContent = 'ğŸ¤ æ­£åœ¨å¬å–è¯­éŸ³...';
                    status.className = 'status';
                };
                
                recognition.onend = function() {
                    isRecording = false;
                    voiceBtn.classList.remove('recording');
                    if (status.textContent === 'ğŸ¤ æ­£åœ¨å¬å–è¯­éŸ³...') {
                        status.textContent = 'â¹ï¸ è¯†åˆ«ç»“æŸ';
                    }
                };
                
                status.textContent = 'âœ… æµè§ˆå™¨æ”¯æŒWeb Speech API';
                status.className = 'status success';
                
            } else {
                status.textContent = 'âŒ æµè§ˆå™¨ä¸æ”¯æŒWeb Speech API';
                status.className = 'status error';
                voiceBtn.disabled = true;
            }
        }
        
        // æŒ‰é’®äº‹ä»¶
        voiceBtn.addEventListener('mousedown', function() {
            if (!recognition || isRecording) return;
            
            try {
                isRecording = true;
                voiceBtn.classList.add('recording');
                recognition.start();
            } catch (error) {
                console.error('å¯åŠ¨è¯†åˆ«å¤±è´¥:', error);
                status.textContent = 'âŒ å¯åŠ¨è¯†åˆ«å¤±è´¥';
                status.className = 'status error';
                isRecording = false;
                voiceBtn.classList.remove('recording');
            }
        });
        
        voiceBtn.addEventListener('mouseup', function() {
            if (!recognition || !isRecording) return;
            
            try {
                recognition.stop();
            } catch (error) {
                console.error('åœæ­¢è¯†åˆ«å¤±è´¥:', error);
            }
        });
        
        // ç§»åŠ¨ç«¯æ”¯æŒ
        voiceBtn.addEventListener('touchstart', function(e) {
            e.preventDefault();
            voiceBtn.dispatchEvent(new Event('mousedown'));
        });
        
        voiceBtn.addEventListener('touchend', function(e) {
            e.preventDefault();
            voiceBtn.dispatchEvent(new Event('mouseup'));
        });
        
        // åˆå§‹åŒ–
        checkSupport();
    </script>
</body>
</html>